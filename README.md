# TokenIDS-Lightweight-Intrusion-Detection-System-using-CNN-Transformer-and-TokenLearner

Achieving **99.56% accuracy** on the NSL-KDD dataset, this project introduces a novel, lightweight hybrid architecture combining CNN, Transformer with Learnable Positional Encoding, TokenLearner, SE blocks, and Bi-Directional Cross-Attention for effective Intrusion Detection.

## ğŸ” Overview

Intrusion Detection Systems (IDS) are critical for ensuring cybersecurity in networks. This model leverages both local and global feature extraction via:
- **CNN** for local pattern learning
- **Transformer** with **Learnable Positional Encoding** for global dependency capture
- **TokenLearner** to dynamically reduce feature tokens
- **Squeeze-and-Excitation (SE)** block for channel-wise attention
- **Bi-Directional Cross-Attention** between CNN and Transformer outputs
- **Attention Pooling** for robust feature aggregation

## ğŸš€ Key Features
- Achieves **99.56% accuracy** on the NSL-KDD dataset
- Lightweight design with < 200K trainable parameters
- Attention-based fusion and pooling for high discrimination
- Visualization support: ROC, PR Curve, Confusion Matrix, Training plots

## ğŸ“Š Results

| Metric        | Score     |
|---------------|-----------|
| Accuracy      | 99.56%    |
| AUC-ROC       | > 0.99    |
| Precision     | High      |
| Recall        | High      |

## ğŸ“ Dataset

We use the **NSL-KDD** dataset:
- [KDDTrain+.txt](https://www.unb.ca/cic/datasets/nsl.html)
- Categorical features are one-hot encoded
- Features scaled using RobustScaler

## ğŸ—ï¸ Architecture

Input â CNN â SE Block â TokenLearner â”
â”œâ”€â”€ Cross-Attention â Pooling â Dense â Output
Input â Transformer â TokenLearner â”€â”€â”€â”˜


## ğŸ§ª How to Run

### Prerequisites

- Python â‰¥ 3.7
- TensorFlow â‰¥ 2.10
- pandas, numpy, sklearn, seaborn, matplotlib

### Training
python ids_detection.py



